{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9I1rlPTh3GEVOoAZPIQuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaBulychev/Randomised-Smoothing/blob/main/Certified_Robustness_Randomised_Smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from scipy.stats import norm, binom_test\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from statsmodels.stats.proportion import proportion_confint\n",
        "from torchvision import transforms, datasets\n",
        "from typing import *\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import *\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from time import time\n",
        "\n",
        "import datetime\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ZYDLcEh7WVwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Build VGG Model { form-width: \"200px\" }\n",
        "\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "# Image preprocessing modules\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "#######\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "########\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True,\n",
        "                                             transform=transform_train,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False,\n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)\n",
        "\n",
        "model = VGG('VGG19').to(device)"
      ],
      "metadata": {
        "id": "mHpYPXnyREIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749f2284-d9eb-431a-b524-df790d83ee57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15865859.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 271075.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5066412.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22562462.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 102261973.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train model with noise { form-width: \"200px\" }\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "# To choose one specific noise distribution:\n",
        "# noise_sd = 0.5\n",
        "\n",
        "# To choose noise randomly:\n",
        "noise_sd = [0, 0.12, 0.25, 0.5, 1]\n",
        "\n",
        "b_size =  100\n",
        "num_epochs = 90\n",
        "\n",
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "if not pretrained_model:\n",
        "    # Train the model\n",
        "    total_step = len(train_loader)\n",
        "    curr_lr = learning_rate\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            images = images + torch.randn_like(images, device='cuda') * random.choice(noise_sd)\n",
        "            # If one specific noise distribution:\n",
        "            #images = images + torch.randn_like(images, device='cuda') * noise_sd\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "        # Decay learning rate\n",
        "        if (epoch+1) % 20 == 0:\n",
        "            curr_lr /= 3\n",
        "            update_lr(optimizer, curr_lr)\n",
        "\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Y4AN5SWwdM",
        "outputId": "35a976c0-4974-4863-9062-1018f1c965c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/90], Step [100/500] Loss: 1.9665\n",
            "Epoch [1/90], Step [200/500] Loss: 1.6855\n",
            "Epoch [1/90], Step [300/500] Loss: 2.0526\n",
            "Epoch [1/90], Step [400/500] Loss: 1.6809\n",
            "Epoch [1/90], Step [500/500] Loss: 1.7155\n",
            "Epoch [2/90], Step [100/500] Loss: 1.7585\n",
            "Epoch [2/90], Step [200/500] Loss: 1.5975\n",
            "Epoch [2/90], Step [300/500] Loss: 2.0448\n",
            "Epoch [2/90], Step [400/500] Loss: 1.2691\n",
            "Epoch [2/90], Step [500/500] Loss: 1.5053\n",
            "Epoch [3/90], Step [100/500] Loss: 1.9212\n",
            "Epoch [3/90], Step [200/500] Loss: 1.4654\n",
            "Epoch [3/90], Step [300/500] Loss: 1.1878\n",
            "Epoch [3/90], Step [400/500] Loss: 1.2487\n",
            "Epoch [3/90], Step [500/500] Loss: 1.2960\n",
            "Epoch [4/90], Step [100/500] Loss: 1.3267\n",
            "Epoch [4/90], Step [200/500] Loss: 1.1239\n",
            "Epoch [4/90], Step [300/500] Loss: 1.1785\n",
            "Epoch [4/90], Step [400/500] Loss: 1.5099\n",
            "Epoch [4/90], Step [500/500] Loss: 1.2436\n",
            "Epoch [5/90], Step [100/500] Loss: 1.3286\n",
            "Epoch [5/90], Step [200/500] Loss: 1.1982\n",
            "Epoch [5/90], Step [300/500] Loss: 1.8186\n",
            "Epoch [5/90], Step [400/500] Loss: 1.3291\n",
            "Epoch [5/90], Step [500/500] Loss: 0.9590\n",
            "Epoch [6/90], Step [100/500] Loss: 0.8043\n",
            "Epoch [6/90], Step [200/500] Loss: 1.0518\n",
            "Epoch [6/90], Step [300/500] Loss: 1.1876\n",
            "Epoch [6/90], Step [400/500] Loss: 0.7044\n",
            "Epoch [6/90], Step [500/500] Loss: 1.0785\n",
            "Epoch [7/90], Step [100/500] Loss: 1.2306\n",
            "Epoch [7/90], Step [200/500] Loss: 0.9615\n",
            "Epoch [7/90], Step [300/500] Loss: 1.0908\n",
            "Epoch [7/90], Step [400/500] Loss: 0.9103\n",
            "Epoch [7/90], Step [500/500] Loss: 0.8326\n",
            "Epoch [8/90], Step [100/500] Loss: 1.1096\n",
            "Epoch [8/90], Step [200/500] Loss: 1.8351\n",
            "Epoch [8/90], Step [300/500] Loss: 0.9867\n",
            "Epoch [8/90], Step [400/500] Loss: 1.8063\n",
            "Epoch [8/90], Step [500/500] Loss: 0.9505\n",
            "Epoch [9/90], Step [100/500] Loss: 0.8253\n",
            "Epoch [9/90], Step [200/500] Loss: 1.7628\n",
            "Epoch [9/90], Step [300/500] Loss: 0.9328\n",
            "Epoch [9/90], Step [400/500] Loss: 1.7110\n",
            "Epoch [9/90], Step [500/500] Loss: 0.8979\n",
            "Epoch [10/90], Step [100/500] Loss: 1.0901\n",
            "Epoch [10/90], Step [200/500] Loss: 1.8290\n",
            "Epoch [10/90], Step [300/500] Loss: 1.0398\n",
            "Epoch [10/90], Step [400/500] Loss: 1.3819\n",
            "Epoch [10/90], Step [500/500] Loss: 1.2817\n",
            "Epoch [11/90], Step [100/500] Loss: 1.6666\n",
            "Epoch [11/90], Step [200/500] Loss: 0.8331\n",
            "Epoch [11/90], Step [300/500] Loss: 1.2802\n",
            "Epoch [11/90], Step [400/500] Loss: 0.6905\n",
            "Epoch [11/90], Step [500/500] Loss: 0.8010\n",
            "Epoch [12/90], Step [100/500] Loss: 1.7254\n",
            "Epoch [12/90], Step [200/500] Loss: 1.0463\n",
            "Epoch [12/90], Step [300/500] Loss: 1.4945\n",
            "Epoch [12/90], Step [400/500] Loss: 1.1151\n",
            "Epoch [12/90], Step [500/500] Loss: 0.7931\n",
            "Epoch [13/90], Step [100/500] Loss: 0.7058\n",
            "Epoch [13/90], Step [200/500] Loss: 1.5506\n",
            "Epoch [13/90], Step [300/500] Loss: 1.7177\n",
            "Epoch [13/90], Step [400/500] Loss: 0.7826\n",
            "Epoch [13/90], Step [500/500] Loss: 0.4484\n",
            "Epoch [14/90], Step [100/500] Loss: 1.3776\n",
            "Epoch [14/90], Step [200/500] Loss: 1.0371\n",
            "Epoch [14/90], Step [300/500] Loss: 0.8355\n",
            "Epoch [14/90], Step [400/500] Loss: 1.0634\n",
            "Epoch [14/90], Step [500/500] Loss: 0.6070\n",
            "Epoch [15/90], Step [100/500] Loss: 0.8880\n",
            "Epoch [15/90], Step [200/500] Loss: 1.6168\n",
            "Epoch [15/90], Step [300/500] Loss: 0.4795\n",
            "Epoch [15/90], Step [400/500] Loss: 0.7251\n",
            "Epoch [15/90], Step [500/500] Loss: 0.9819\n",
            "Epoch [16/90], Step [100/500] Loss: 1.1661\n",
            "Epoch [16/90], Step [200/500] Loss: 1.6252\n",
            "Epoch [16/90], Step [300/500] Loss: 0.4577\n",
            "Epoch [16/90], Step [400/500] Loss: 1.0135\n",
            "Epoch [16/90], Step [500/500] Loss: 0.5264\n",
            "Epoch [17/90], Step [100/500] Loss: 0.7559\n",
            "Epoch [17/90], Step [200/500] Loss: 1.6559\n",
            "Epoch [17/90], Step [300/500] Loss: 0.7086\n",
            "Epoch [17/90], Step [400/500] Loss: 0.5759\n",
            "Epoch [17/90], Step [500/500] Loss: 0.9056\n",
            "Epoch [18/90], Step [100/500] Loss: 0.8395\n",
            "Epoch [18/90], Step [200/500] Loss: 1.6924\n",
            "Epoch [18/90], Step [300/500] Loss: 0.4597\n",
            "Epoch [18/90], Step [400/500] Loss: 1.1739\n",
            "Epoch [18/90], Step [500/500] Loss: 0.6426\n",
            "Epoch [19/90], Step [100/500] Loss: 1.2644\n",
            "Epoch [19/90], Step [200/500] Loss: 1.7582\n",
            "Epoch [19/90], Step [300/500] Loss: 0.7477\n",
            "Epoch [19/90], Step [400/500] Loss: 0.5369\n",
            "Epoch [19/90], Step [500/500] Loss: 1.8696\n",
            "Epoch [20/90], Step [100/500] Loss: 0.4933\n",
            "Epoch [20/90], Step [200/500] Loss: 1.2265\n",
            "Epoch [20/90], Step [300/500] Loss: 0.9510\n",
            "Epoch [20/90], Step [400/500] Loss: 1.6083\n",
            "Epoch [20/90], Step [500/500] Loss: 1.7100\n",
            "Epoch [21/90], Step [100/500] Loss: 0.6404\n",
            "Epoch [21/90], Step [200/500] Loss: 1.5331\n",
            "Epoch [21/90], Step [300/500] Loss: 1.6058\n",
            "Epoch [21/90], Step [400/500] Loss: 0.2905\n",
            "Epoch [21/90], Step [500/500] Loss: 1.5493\n",
            "Epoch [22/90], Step [100/500] Loss: 1.3015\n",
            "Epoch [22/90], Step [200/500] Loss: 0.4472\n",
            "Epoch [22/90], Step [300/500] Loss: 1.5806\n",
            "Epoch [22/90], Step [400/500] Loss: 0.7463\n",
            "Epoch [22/90], Step [500/500] Loss: 0.3430\n",
            "Epoch [23/90], Step [100/500] Loss: 0.4159\n",
            "Epoch [23/90], Step [200/500] Loss: 0.4296\n",
            "Epoch [23/90], Step [300/500] Loss: 0.7958\n",
            "Epoch [23/90], Step [400/500] Loss: 0.8094\n",
            "Epoch [23/90], Step [500/500] Loss: 0.3388\n",
            "Epoch [24/90], Step [100/500] Loss: 0.9503\n",
            "Epoch [24/90], Step [200/500] Loss: 0.7395\n",
            "Epoch [24/90], Step [300/500] Loss: 0.9022\n",
            "Epoch [24/90], Step [400/500] Loss: 0.2308\n",
            "Epoch [24/90], Step [500/500] Loss: 0.9004\n",
            "Epoch [25/90], Step [100/500] Loss: 0.4336\n",
            "Epoch [25/90], Step [200/500] Loss: 0.6935\n",
            "Epoch [25/90], Step [300/500] Loss: 0.6639\n",
            "Epoch [25/90], Step [400/500] Loss: 1.1251\n",
            "Epoch [25/90], Step [500/500] Loss: 0.4803\n",
            "Epoch [26/90], Step [100/500] Loss: 0.6792\n",
            "Epoch [26/90], Step [200/500] Loss: 0.7363\n",
            "Epoch [26/90], Step [300/500] Loss: 1.5496\n",
            "Epoch [26/90], Step [400/500] Loss: 0.9840\n",
            "Epoch [26/90], Step [500/500] Loss: 0.5534\n",
            "Epoch [27/90], Step [100/500] Loss: 0.3045\n",
            "Epoch [27/90], Step [200/500] Loss: 1.5382\n",
            "Epoch [27/90], Step [300/500] Loss: 0.7178\n",
            "Epoch [27/90], Step [400/500] Loss: 0.7222\n",
            "Epoch [27/90], Step [500/500] Loss: 0.5336\n",
            "Epoch [28/90], Step [100/500] Loss: 0.5518\n",
            "Epoch [28/90], Step [200/500] Loss: 0.4023\n",
            "Epoch [28/90], Step [300/500] Loss: 0.4500\n",
            "Epoch [28/90], Step [400/500] Loss: 1.1665\n",
            "Epoch [28/90], Step [500/500] Loss: 1.1507\n",
            "Epoch [29/90], Step [100/500] Loss: 0.5064\n",
            "Epoch [29/90], Step [200/500] Loss: 0.3395\n",
            "Epoch [29/90], Step [300/500] Loss: 1.1923\n",
            "Epoch [29/90], Step [400/500] Loss: 0.4800\n",
            "Epoch [29/90], Step [500/500] Loss: 1.5184\n",
            "Epoch [30/90], Step [100/500] Loss: 0.3177\n",
            "Epoch [30/90], Step [200/500] Loss: 0.4328\n",
            "Epoch [30/90], Step [300/500] Loss: 0.3127\n",
            "Epoch [30/90], Step [400/500] Loss: 0.4158\n",
            "Epoch [30/90], Step [500/500] Loss: 1.7815\n",
            "Epoch [31/90], Step [100/500] Loss: 1.4312\n",
            "Epoch [31/90], Step [200/500] Loss: 1.4178\n",
            "Epoch [31/90], Step [300/500] Loss: 0.5006\n",
            "Epoch [31/90], Step [400/500] Loss: 0.2382\n",
            "Epoch [31/90], Step [500/500] Loss: 0.5980\n",
            "Epoch [32/90], Step [100/500] Loss: 1.6426\n",
            "Epoch [32/90], Step [200/500] Loss: 1.4986\n",
            "Epoch [32/90], Step [300/500] Loss: 0.3535\n",
            "Epoch [32/90], Step [400/500] Loss: 0.4525\n",
            "Epoch [32/90], Step [500/500] Loss: 0.9482\n",
            "Epoch [33/90], Step [100/500] Loss: 1.5420\n",
            "Epoch [33/90], Step [200/500] Loss: 1.0475\n",
            "Epoch [33/90], Step [300/500] Loss: 0.5932\n",
            "Epoch [33/90], Step [400/500] Loss: 0.3893\n",
            "Epoch [33/90], Step [500/500] Loss: 0.3201\n",
            "Epoch [34/90], Step [100/500] Loss: 0.7076\n",
            "Epoch [34/90], Step [200/500] Loss: 0.9827\n",
            "Epoch [34/90], Step [300/500] Loss: 0.3027\n",
            "Epoch [34/90], Step [400/500] Loss: 0.5865\n",
            "Epoch [34/90], Step [500/500] Loss: 0.4405\n",
            "Epoch [35/90], Step [100/500] Loss: 0.4958\n",
            "Epoch [35/90], Step [200/500] Loss: 0.7517\n",
            "Epoch [35/90], Step [300/500] Loss: 1.0907\n",
            "Epoch [35/90], Step [400/500] Loss: 1.0702\n",
            "Epoch [35/90], Step [500/500] Loss: 0.9161\n",
            "Epoch [36/90], Step [100/500] Loss: 0.7093\n",
            "Epoch [36/90], Step [200/500] Loss: 1.0933\n",
            "Epoch [36/90], Step [300/500] Loss: 0.6465\n",
            "Epoch [36/90], Step [400/500] Loss: 0.3028\n",
            "Epoch [36/90], Step [500/500] Loss: 0.4043\n",
            "Epoch [37/90], Step [100/500] Loss: 0.9361\n",
            "Epoch [37/90], Step [200/500] Loss: 0.2985\n",
            "Epoch [37/90], Step [300/500] Loss: 0.5891\n",
            "Epoch [37/90], Step [400/500] Loss: 0.3018\n",
            "Epoch [37/90], Step [500/500] Loss: 1.3196\n",
            "Epoch [38/90], Step [100/500] Loss: 0.3334\n",
            "Epoch [38/90], Step [200/500] Loss: 1.1003\n",
            "Epoch [38/90], Step [300/500] Loss: 0.6492\n",
            "Epoch [38/90], Step [400/500] Loss: 1.4787\n",
            "Epoch [38/90], Step [500/500] Loss: 0.7373\n",
            "Epoch [39/90], Step [100/500] Loss: 0.3383\n",
            "Epoch [39/90], Step [200/500] Loss: 0.6459\n",
            "Epoch [39/90], Step [300/500] Loss: 0.7491\n",
            "Epoch [39/90], Step [400/500] Loss: 1.6474\n",
            "Epoch [39/90], Step [500/500] Loss: 0.6901\n",
            "Epoch [40/90], Step [100/500] Loss: 0.8846\n",
            "Epoch [40/90], Step [200/500] Loss: 1.6208\n",
            "Epoch [40/90], Step [300/500] Loss: 0.4653\n",
            "Epoch [40/90], Step [400/500] Loss: 0.6252\n",
            "Epoch [40/90], Step [500/500] Loss: 1.5843\n",
            "Epoch [41/90], Step [100/500] Loss: 0.9684\n",
            "Epoch [41/90], Step [200/500] Loss: 0.9302\n",
            "Epoch [41/90], Step [300/500] Loss: 0.4674\n",
            "Epoch [41/90], Step [400/500] Loss: 0.2601\n",
            "Epoch [41/90], Step [500/500] Loss: 0.2382\n",
            "Epoch [42/90], Step [100/500] Loss: 0.1629\n",
            "Epoch [42/90], Step [200/500] Loss: 0.5317\n",
            "Epoch [42/90], Step [300/500] Loss: 0.2570\n",
            "Epoch [42/90], Step [400/500] Loss: 1.0024\n",
            "Epoch [42/90], Step [500/500] Loss: 0.9641\n",
            "Epoch [43/90], Step [100/500] Loss: 0.5037\n",
            "Epoch [43/90], Step [200/500] Loss: 0.4528\n",
            "Epoch [43/90], Step [300/500] Loss: 0.3144\n",
            "Epoch [43/90], Step [400/500] Loss: 0.1634\n",
            "Epoch [43/90], Step [500/500] Loss: 1.6463\n",
            "Epoch [44/90], Step [100/500] Loss: 0.9466\n",
            "Epoch [44/90], Step [200/500] Loss: 0.5652\n",
            "Epoch [44/90], Step [300/500] Loss: 0.9642\n",
            "Epoch [44/90], Step [400/500] Loss: 1.3946\n",
            "Epoch [44/90], Step [500/500] Loss: 0.5225\n",
            "Epoch [45/90], Step [100/500] Loss: 1.0590\n",
            "Epoch [45/90], Step [200/500] Loss: 0.8995\n",
            "Epoch [45/90], Step [300/500] Loss: 1.5656\n",
            "Epoch [45/90], Step [400/500] Loss: 0.4029\n",
            "Epoch [45/90], Step [500/500] Loss: 0.7730\n",
            "Epoch [46/90], Step [100/500] Loss: 0.4683\n",
            "Epoch [46/90], Step [200/500] Loss: 0.2325\n",
            "Epoch [46/90], Step [300/500] Loss: 0.3252\n",
            "Epoch [46/90], Step [400/500] Loss: 0.2630\n",
            "Epoch [46/90], Step [500/500] Loss: 0.2930\n",
            "Epoch [47/90], Step [100/500] Loss: 0.4990\n",
            "Epoch [47/90], Step [200/500] Loss: 0.1418\n",
            "Epoch [47/90], Step [300/500] Loss: 1.5819\n",
            "Epoch [47/90], Step [400/500] Loss: 0.5008\n",
            "Epoch [47/90], Step [500/500] Loss: 0.3896\n",
            "Epoch [48/90], Step [100/500] Loss: 1.4941\n",
            "Epoch [48/90], Step [200/500] Loss: 0.1895\n",
            "Epoch [48/90], Step [300/500] Loss: 1.5080\n",
            "Epoch [48/90], Step [400/500] Loss: 0.9598\n",
            "Epoch [48/90], Step [500/500] Loss: 0.2190\n",
            "Epoch [49/90], Step [100/500] Loss: 0.9538\n",
            "Epoch [49/90], Step [200/500] Loss: 0.2879\n",
            "Epoch [49/90], Step [300/500] Loss: 1.0434\n",
            "Epoch [49/90], Step [400/500] Loss: 0.2680\n",
            "Epoch [49/90], Step [500/500] Loss: 0.4222\n",
            "Epoch [50/90], Step [100/500] Loss: 1.5290\n",
            "Epoch [50/90], Step [200/500] Loss: 0.2428\n",
            "Epoch [50/90], Step [300/500] Loss: 1.4950\n",
            "Epoch [50/90], Step [400/500] Loss: 1.5722\n",
            "Epoch [50/90], Step [500/500] Loss: 1.2962\n",
            "Epoch [51/90], Step [100/500] Loss: 0.2949\n",
            "Epoch [51/90], Step [200/500] Loss: 0.2199\n",
            "Epoch [51/90], Step [300/500] Loss: 0.5549\n",
            "Epoch [51/90], Step [400/500] Loss: 1.0664\n",
            "Epoch [51/90], Step [500/500] Loss: 0.9597\n",
            "Epoch [52/90], Step [100/500] Loss: 0.3093\n",
            "Epoch [52/90], Step [200/500] Loss: 0.8296\n",
            "Epoch [52/90], Step [300/500] Loss: 1.5677\n",
            "Epoch [52/90], Step [400/500] Loss: 0.4916\n",
            "Epoch [52/90], Step [500/500] Loss: 0.1638\n",
            "Epoch [53/90], Step [100/500] Loss: 0.3057\n",
            "Epoch [53/90], Step [200/500] Loss: 0.2551\n",
            "Epoch [53/90], Step [300/500] Loss: 0.2851\n",
            "Epoch [53/90], Step [400/500] Loss: 0.6360\n",
            "Epoch [53/90], Step [500/500] Loss: 0.5892\n",
            "Epoch [54/90], Step [100/500] Loss: 0.2089\n",
            "Epoch [54/90], Step [200/500] Loss: 0.2166\n",
            "Epoch [54/90], Step [300/500] Loss: 0.8440\n",
            "Epoch [54/90], Step [400/500] Loss: 0.3533\n",
            "Epoch [54/90], Step [500/500] Loss: 1.4032\n",
            "Epoch [55/90], Step [100/500] Loss: 0.2041\n",
            "Epoch [55/90], Step [200/500] Loss: 1.4011\n",
            "Epoch [55/90], Step [300/500] Loss: 0.3231\n",
            "Epoch [55/90], Step [400/500] Loss: 0.9910\n",
            "Epoch [55/90], Step [500/500] Loss: 1.0904\n",
            "Epoch [56/90], Step [100/500] Loss: 0.1667\n",
            "Epoch [56/90], Step [200/500] Loss: 1.6344\n",
            "Epoch [56/90], Step [300/500] Loss: 0.2121\n",
            "Epoch [56/90], Step [400/500] Loss: 1.0566\n",
            "Epoch [56/90], Step [500/500] Loss: 1.4484\n",
            "Epoch [57/90], Step [100/500] Loss: 0.5214\n",
            "Epoch [57/90], Step [200/500] Loss: 0.2437\n",
            "Epoch [57/90], Step [300/500] Loss: 1.6392\n",
            "Epoch [57/90], Step [400/500] Loss: 0.8884\n",
            "Epoch [57/90], Step [500/500] Loss: 1.4398\n",
            "Epoch [58/90], Step [100/500] Loss: 1.0561\n",
            "Epoch [58/90], Step [200/500] Loss: 0.9245\n",
            "Epoch [58/90], Step [300/500] Loss: 0.1669\n",
            "Epoch [58/90], Step [400/500] Loss: 0.5002\n",
            "Epoch [58/90], Step [500/500] Loss: 0.3454\n",
            "Epoch [59/90], Step [100/500] Loss: 0.2067\n",
            "Epoch [59/90], Step [200/500] Loss: 1.5180\n",
            "Epoch [59/90], Step [300/500] Loss: 0.2232\n",
            "Epoch [59/90], Step [400/500] Loss: 0.1297\n",
            "Epoch [59/90], Step [500/500] Loss: 1.4300\n",
            "Epoch [60/90], Step [100/500] Loss: 0.4648\n",
            "Epoch [60/90], Step [200/500] Loss: 0.3832\n",
            "Epoch [60/90], Step [300/500] Loss: 0.2022\n",
            "Epoch [60/90], Step [400/500] Loss: 1.5173\n",
            "Epoch [60/90], Step [500/500] Loss: 1.5754\n",
            "Epoch [61/90], Step [100/500] Loss: 1.0165\n",
            "Epoch [61/90], Step [200/500] Loss: 0.1698\n",
            "Epoch [61/90], Step [300/500] Loss: 0.8552\n",
            "Epoch [61/90], Step [400/500] Loss: 1.4108\n",
            "Epoch [61/90], Step [500/500] Loss: 0.1269\n",
            "Epoch [62/90], Step [100/500] Loss: 0.5616\n",
            "Epoch [62/90], Step [200/500] Loss: 0.1125\n",
            "Epoch [62/90], Step [300/500] Loss: 1.4583\n",
            "Epoch [62/90], Step [400/500] Loss: 0.2622\n",
            "Epoch [62/90], Step [500/500] Loss: 0.3063\n",
            "Epoch [63/90], Step [100/500] Loss: 0.2162\n",
            "Epoch [63/90], Step [200/500] Loss: 0.0958\n",
            "Epoch [63/90], Step [300/500] Loss: 1.4714\n",
            "Epoch [63/90], Step [400/500] Loss: 0.8988\n",
            "Epoch [63/90], Step [500/500] Loss: 0.9379\n",
            "Epoch [64/90], Step [100/500] Loss: 1.5513\n",
            "Epoch [64/90], Step [200/500] Loss: 0.4598\n",
            "Epoch [64/90], Step [300/500] Loss: 0.1349\n",
            "Epoch [64/90], Step [400/500] Loss: 0.4334\n",
            "Epoch [64/90], Step [500/500] Loss: 0.2496\n",
            "Epoch [65/90], Step [100/500] Loss: 0.3666\n",
            "Epoch [65/90], Step [200/500] Loss: 1.5343\n",
            "Epoch [65/90], Step [300/500] Loss: 0.1250\n",
            "Epoch [65/90], Step [400/500] Loss: 0.8626\n",
            "Epoch [65/90], Step [500/500] Loss: 0.1376\n",
            "Epoch [66/90], Step [100/500] Loss: 0.1364\n",
            "Epoch [66/90], Step [200/500] Loss: 0.0702\n",
            "Epoch [66/90], Step [300/500] Loss: 0.5093\n",
            "Epoch [66/90], Step [400/500] Loss: 0.7023\n",
            "Epoch [66/90], Step [500/500] Loss: 0.2334\n",
            "Epoch [67/90], Step [100/500] Loss: 0.7790\n",
            "Epoch [67/90], Step [200/500] Loss: 0.4565\n",
            "Epoch [67/90], Step [300/500] Loss: 1.4710\n",
            "Epoch [67/90], Step [400/500] Loss: 0.0739\n",
            "Epoch [67/90], Step [500/500] Loss: 0.1011\n",
            "Epoch [68/90], Step [100/500] Loss: 0.4541\n",
            "Epoch [68/90], Step [200/500] Loss: 1.3708\n",
            "Epoch [68/90], Step [300/500] Loss: 1.4931\n",
            "Epoch [68/90], Step [400/500] Loss: 1.3892\n",
            "Epoch [68/90], Step [500/500] Loss: 0.1189\n",
            "Epoch [69/90], Step [100/500] Loss: 0.8231\n",
            "Epoch [69/90], Step [200/500] Loss: 0.4277\n",
            "Epoch [69/90], Step [300/500] Loss: 0.2471\n",
            "Epoch [69/90], Step [400/500] Loss: 0.8799\n",
            "Epoch [69/90], Step [500/500] Loss: 0.7486\n",
            "Epoch [70/90], Step [100/500] Loss: 1.0247\n",
            "Epoch [70/90], Step [200/500] Loss: 0.1693\n",
            "Epoch [70/90], Step [300/500] Loss: 0.1517\n",
            "Epoch [70/90], Step [400/500] Loss: 0.1715\n",
            "Epoch [70/90], Step [500/500] Loss: 0.3435\n",
            "Epoch [71/90], Step [100/500] Loss: 0.7925\n",
            "Epoch [71/90], Step [200/500] Loss: 1.3629\n",
            "Epoch [71/90], Step [300/500] Loss: 1.6305\n",
            "Epoch [71/90], Step [400/500] Loss: 0.0893\n",
            "Epoch [71/90], Step [500/500] Loss: 0.0943\n",
            "Epoch [72/90], Step [100/500] Loss: 0.1631\n",
            "Epoch [72/90], Step [200/500] Loss: 0.8356\n",
            "Epoch [72/90], Step [300/500] Loss: 1.6063\n",
            "Epoch [72/90], Step [400/500] Loss: 0.1939\n",
            "Epoch [72/90], Step [500/500] Loss: 0.3200\n",
            "Epoch [73/90], Step [100/500] Loss: 0.1939\n",
            "Epoch [73/90], Step [200/500] Loss: 0.7507\n",
            "Epoch [73/90], Step [300/500] Loss: 0.2508\n",
            "Epoch [73/90], Step [400/500] Loss: 0.7833\n",
            "Epoch [73/90], Step [500/500] Loss: 0.3768\n",
            "Epoch [74/90], Step [100/500] Loss: 0.4902\n",
            "Epoch [74/90], Step [200/500] Loss: 0.1461\n",
            "Epoch [74/90], Step [300/500] Loss: 0.2039\n",
            "Epoch [74/90], Step [400/500] Loss: 0.1222\n",
            "Epoch [74/90], Step [500/500] Loss: 0.3602\n",
            "Epoch [75/90], Step [100/500] Loss: 0.2056\n",
            "Epoch [75/90], Step [200/500] Loss: 0.0884\n",
            "Epoch [75/90], Step [300/500] Loss: 1.5530\n",
            "Epoch [75/90], Step [400/500] Loss: 1.3154\n",
            "Epoch [75/90], Step [500/500] Loss: 0.1414\n",
            "Epoch [76/90], Step [100/500] Loss: 0.9823\n",
            "Epoch [76/90], Step [200/500] Loss: 1.3933\n",
            "Epoch [76/90], Step [300/500] Loss: 1.4230\n",
            "Epoch [76/90], Step [400/500] Loss: 1.3774\n",
            "Epoch [76/90], Step [500/500] Loss: 0.1915\n",
            "Epoch [77/90], Step [100/500] Loss: 0.1177\n",
            "Epoch [77/90], Step [200/500] Loss: 0.8215\n",
            "Epoch [77/90], Step [300/500] Loss: 0.1026\n",
            "Epoch [77/90], Step [400/500] Loss: 0.1973\n",
            "Epoch [77/90], Step [500/500] Loss: 1.3124\n",
            "Epoch [78/90], Step [100/500] Loss: 0.2111\n",
            "Epoch [78/90], Step [200/500] Loss: 0.7832\n",
            "Epoch [78/90], Step [300/500] Loss: 0.1045\n",
            "Epoch [78/90], Step [400/500] Loss: 1.2110\n",
            "Epoch [78/90], Step [500/500] Loss: 1.1695\n",
            "Epoch [79/90], Step [100/500] Loss: 0.3677\n",
            "Epoch [79/90], Step [200/500] Loss: 0.8552\n",
            "Epoch [79/90], Step [300/500] Loss: 1.4712\n",
            "Epoch [79/90], Step [400/500] Loss: 0.2433\n",
            "Epoch [79/90], Step [500/500] Loss: 1.3565\n",
            "Epoch [80/90], Step [100/500] Loss: 0.0778\n",
            "Epoch [80/90], Step [200/500] Loss: 0.1829\n",
            "Epoch [80/90], Step [300/500] Loss: 0.4267\n",
            "Epoch [80/90], Step [400/500] Loss: 0.0703\n",
            "Epoch [80/90], Step [500/500] Loss: 0.1303\n",
            "Epoch [81/90], Step [100/500] Loss: 1.5533\n",
            "Epoch [81/90], Step [200/500] Loss: 0.8763\n",
            "Epoch [81/90], Step [300/500] Loss: 0.1776\n",
            "Epoch [81/90], Step [400/500] Loss: 0.0581\n",
            "Epoch [81/90], Step [500/500] Loss: 0.6891\n",
            "Epoch [82/90], Step [100/500] Loss: 1.4668\n",
            "Epoch [82/90], Step [200/500] Loss: 0.0682\n",
            "Epoch [82/90], Step [300/500] Loss: 0.1025\n",
            "Epoch [82/90], Step [400/500] Loss: 0.4695\n",
            "Epoch [82/90], Step [500/500] Loss: 0.1526\n",
            "Epoch [83/90], Step [100/500] Loss: 0.3858\n",
            "Epoch [83/90], Step [200/500] Loss: 0.9615\n",
            "Epoch [83/90], Step [300/500] Loss: 0.3906\n",
            "Epoch [83/90], Step [400/500] Loss: 1.0729\n",
            "Epoch [83/90], Step [500/500] Loss: 1.4010\n",
            "Epoch [84/90], Step [100/500] Loss: 0.0590\n",
            "Epoch [84/90], Step [200/500] Loss: 1.3896\n",
            "Epoch [84/90], Step [300/500] Loss: 0.0830\n",
            "Epoch [84/90], Step [400/500] Loss: 0.3470\n",
            "Epoch [84/90], Step [500/500] Loss: 0.0956\n",
            "Epoch [85/90], Step [100/500] Loss: 0.9519\n",
            "Epoch [85/90], Step [200/500] Loss: 0.1511\n",
            "Epoch [85/90], Step [300/500] Loss: 0.2100\n",
            "Epoch [85/90], Step [400/500] Loss: 0.1122\n",
            "Epoch [85/90], Step [500/500] Loss: 1.5056\n",
            "Epoch [86/90], Step [100/500] Loss: 0.0579\n",
            "Epoch [86/90], Step [200/500] Loss: 0.9254\n",
            "Epoch [86/90], Step [300/500] Loss: 1.0218\n",
            "Epoch [86/90], Step [400/500] Loss: 0.1857\n",
            "Epoch [86/90], Step [500/500] Loss: 0.1561\n",
            "Epoch [87/90], Step [100/500] Loss: 0.1423\n",
            "Epoch [87/90], Step [200/500] Loss: 0.2802\n",
            "Epoch [87/90], Step [300/500] Loss: 1.5203\n",
            "Epoch [87/90], Step [400/500] Loss: 0.1157\n",
            "Epoch [87/90], Step [500/500] Loss: 0.4785\n",
            "Epoch [88/90], Step [100/500] Loss: 0.0689\n",
            "Epoch [88/90], Step [200/500] Loss: 0.4269\n",
            "Epoch [88/90], Step [300/500] Loss: 0.3927\n",
            "Epoch [88/90], Step [400/500] Loss: 0.9158\n",
            "Epoch [88/90], Step [500/500] Loss: 1.4820\n",
            "Epoch [89/90], Step [100/500] Loss: 0.3010\n",
            "Epoch [89/90], Step [200/500] Loss: 0.8452\n",
            "Epoch [89/90], Step [300/500] Loss: 0.1367\n",
            "Epoch [89/90], Step [400/500] Loss: 0.9900\n",
            "Epoch [89/90], Step [500/500] Loss: 0.3801\n",
            "Epoch [90/90], Step [100/500] Loss: 0.1394\n",
            "Epoch [90/90], Step [200/500] Loss: 0.4746\n",
            "Epoch [90/90], Step [300/500] Loss: 1.3920\n",
            "Epoch [90/90], Step [400/500] Loss: 0.1145\n",
            "Epoch [90/90], Step [500/500] Loss: 0.0620\n",
            "Accuracy of the model on the test images: 61.69 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save model { form-width: \"200px\" }\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/VGG19_cifar10_rand.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFCZg9bShbwR",
        "outputId": "dfaa3076-617a-4cbb-a13e-78f697d482d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Construct smoothed classifier { form-width: \"200px\" }\n",
        "\n",
        "class Smooth(object):\n",
        "    \"\"\"A smoothed classifier g \"\"\"\n",
        "\n",
        "    # to abstain, Smooth returns this int\n",
        "    ABSTAIN = -1\n",
        "\n",
        "    def __init__(self, base_classifier: torch.nn.Module, num_classes: int, sigma: float):\n",
        "        \"\"\"\n",
        "        :param base_classifier: maps from [batch x channel x height x width] to [batch x num_classes]\n",
        "        :param num_classes:\n",
        "        :param sigma: the noise level hyperparameter\n",
        "        \"\"\"\n",
        "        self.base_classifier = base_classifier\n",
        "        self.num_classes = num_classes\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def certify(self, x: torch.tensor, n0: int, n: int, alpha: float, batch_size: int) -> (int, float):\n",
        "        \"\"\" Monte Carlo algorithm for certifying that g's prediction around x is constant within some L2 radius.\n",
        "        With probability at least 1 - alpha, the class returned by this method will equal g(x), and g's prediction will\n",
        "        robust within a L2 ball of radius R around x.\n",
        "        :param x: the input [channel x height x width]\n",
        "        :param n0: the number of Monte Carlo samples to use for selection\n",
        "        :param n: the number of Monte Carlo samples to use for estimation\n",
        "        :param alpha: the failure probability\n",
        "        :param batch_size: batch size to use when evaluating the base classifier\n",
        "        :return: (predicted class, certified radius)\n",
        "                 in the case of abstention, the class will be ABSTAIN and the radius 0.\n",
        "        \"\"\"\n",
        "        self.base_classifier.eval()\n",
        "        # draw samples of f(x+ epsilon)\n",
        "        counts_selection = self._sample_noise(x, n0, batch_size)\n",
        "        # use these samples to take a guess at the top class\n",
        "        cAHat = counts_selection.argmax().item()\n",
        "        # draw more samples of f(x + epsilon)\n",
        "        counts_estimation = self._sample_noise(x, n, batch_size)\n",
        "        # use these samples to estimate a lower bound on pA\n",
        "        nA = counts_estimation[cAHat].item()\n",
        "        pABar = self._lower_confidence_bound(nA, n, alpha)\n",
        "        if pABar < 0.5:\n",
        "            return Smooth.ABSTAIN, 0.0\n",
        "        else:\n",
        "            radius = self.sigma * norm.ppf(pABar)\n",
        "            return cAHat, radius\n",
        "\n",
        "    def predict(self, x: torch.tensor, n: int, alpha: float, batch_size: int) -> int:\n",
        "        \"\"\" Monte Carlo algorithm for evaluating the prediction of g at x.  With probability at least 1 - alpha, the\n",
        "        class returned by this method will equal g(x).\n",
        "        This function uses the hypothesis test described in https://arxiv.org/abs/1610.03944\n",
        "        for identifying the top category of a multinomial distribution.\n",
        "        :param x: the input [channel x height x width]\n",
        "        :param n: the number of Monte Carlo samples to use\n",
        "        :param alpha: the failure probability\n",
        "        :param batch_size: batch size to use when evaluating the base classifier\n",
        "        :return: the predicted class, or ABSTAIN\n",
        "        \"\"\"\n",
        "        self.base_classifier.eval()\n",
        "        counts = self._sample_noise(x, n, batch_size)\n",
        "        top2 = counts.argsort()[::-1][:2]\n",
        "        count1 = counts[top2[0]]\n",
        "        count2 = counts[top2[1]]\n",
        "        if binom_test(count1, count1 + count2, p=0.5) > alpha:\n",
        "            return Smooth.ABSTAIN\n",
        "        else:\n",
        "            return top2[0]\n",
        "\n",
        "    def _sample_noise(self, x: torch.tensor, num: int, batch_size) -> np.ndarray:\n",
        "        \"\"\" Sample the base classifier's prediction under noisy corruptions of the input x.\n",
        "        :param x: the input [channel x width x height]\n",
        "        :param num: number of samples to collect\n",
        "        :param batch_size:\n",
        "        :return: an ndarray[int] of length num_classes containing the per-class counts\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            counts = np.zeros(self.num_classes, dtype=int)\n",
        "            for _ in range(ceil(num / batch_size)):\n",
        "                this_batch_size = min(batch_size, num)\n",
        "                num -= this_batch_size\n",
        "\n",
        "                batch = x.repeat((this_batch_size, 1, 1, 1))\n",
        "                if torch.cuda.is_available():\n",
        "                    noise = torch.randn_like(batch, device='cuda') * self.sigma\n",
        "                else:\n",
        "                    noise = torch.randn_like(batch) * self.sigma\n",
        "\n",
        "                predictions = self.base_classifier(batch + noise).argmax(1)\n",
        "                counts += self._count_arr(predictions.cpu().numpy(), self.num_classes)\n",
        "            return counts\n",
        "\n",
        "    def _count_arr(self, arr: np.ndarray, length: int) -> np.ndarray:\n",
        "        counts = np.zeros(length, dtype=int)\n",
        "        for idx in arr:\n",
        "            counts[idx] += 1\n",
        "        return counts\n",
        "\n",
        "    def _lower_confidence_bound(self, NA: int, N: int, alpha: float) -> float:\n",
        "        \"\"\" Returns a (1 - alpha) lower confidence bound on a bernoulli proportion.\n",
        "        This function uses the Clopper-Pearson method.\n",
        "        :param NA: the number of \"successes\"\n",
        "        :param N: the number of total draws\n",
        "        :param alpha: the confidence level\n",
        "        :return: a lower bound on the binomial proportion which holds true w.p at least (1 - alpha) over the samples\n",
        "        \"\"\"\n",
        "        return proportion_confint(NA, N, alpha=2 * alpha, method=\"beta\")[0]"
      ],
      "metadata": {
        "id": "jyQpvOt0HAH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare Datasets { form-width: \"200px\" }\n",
        "\n",
        "IMAGENET_LOC_ENV = \"IMAGENET_DIR\"\n",
        "\n",
        "# list of all datasets\n",
        "DATASETS = [\"imagenet\", \"cifar10\"]\n",
        "\n",
        "\n",
        "def get_dataset(dataset: str, split: str) -> Dataset:\n",
        "    \"\"\"Return the dataset as a PyTorch Dataset object\"\"\"\n",
        "    if dataset == \"imagenet\":\n",
        "        return _imagenet(split)\n",
        "    elif dataset == \"cifar10\":\n",
        "        return _cifar10(split)\n",
        "\n",
        "\n",
        "def get_num_classes(dataset: str):\n",
        "    \"\"\"Return the number of classes in the dataset. \"\"\"\n",
        "    if dataset == \"imagenet\":\n",
        "        return 1000\n",
        "    elif dataset == \"cifar10\":\n",
        "        return 10\n",
        "\n",
        "\n",
        "def get_normalize_layer(dataset: str) -> torch.nn.Module:\n",
        "    \"\"\"Return the dataset's normalization layer\"\"\"\n",
        "    if dataset == \"imagenet\":\n",
        "        return NormalizeLayer(_IMAGENET_MEAN, _IMAGENET_STDDEV)\n",
        "    elif dataset == \"cifar10\":\n",
        "        return NormalizeLayer(_CIFAR10_MEAN, _CIFAR10_STDDEV)\n",
        "\n",
        "\n",
        "_IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "_IMAGENET_STDDEV = [0.229, 0.224, 0.225]\n",
        "\n",
        "_CIFAR10_MEAN = [0.4914, 0.4822, 0.4465]\n",
        "_CIFAR10_STDDEV = [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "\n",
        "def _cifar10(split: str) -> Dataset:\n",
        "    if split == \"train\":\n",
        "        return datasets.CIFAR10(\"./dataset_cache\", train=True, download=True, transform=transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor()\n",
        "        ]))\n",
        "    elif split == \"test\":\n",
        "        return datasets.CIFAR10(\"./dataset_cache\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "def _imagenet(split: str) -> Dataset:\n",
        "    if not IMAGENET_LOC_ENV in os.environ:\n",
        "        raise RuntimeError(\"environment variable for ImageNet directory not set\")\n",
        "\n",
        "    dir = os.environ[IMAGENET_LOC_ENV]\n",
        "    if split == \"train\":\n",
        "        subdir = os.path.join(dir, \"train\")\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomSizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    elif split == \"test\":\n",
        "        subdir = os.path.join(dir, \"val\")\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Scale(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    return datasets.ImageFolder(subdir, transform)\n",
        "\n",
        "\n",
        "class NormalizeLayer(torch.nn.Module):\n",
        "    \"\"\"Standardize the channels of a batch of images by subtracting the dataset mean\n",
        "      and dividing by the dataset standard deviation.\n",
        "      In order to certify radii in original coordinates rather than standardized coordinates, we\n",
        "      add the Gaussian noise _before_ standardizing, which is why we have standardization be the first\n",
        "      layer of the classifier rather than as a part of preprocessing as is typical.\n",
        "      \"\"\"\n",
        "\n",
        "    def __init__(self, means: List[float], sds: List[float]):\n",
        "        \"\"\"\n",
        "        :param means: the channel means\n",
        "        :param sds: the channel standard deviations\n",
        "        \"\"\"\n",
        "        super(NormalizeLayer, self).__init__()\n",
        "        self.means = torch.tensor(means).cuda()\n",
        "        self.sds = torch.tensor(sds).cuda()\n",
        "\n",
        "    def forward(self, input: torch.tensor):\n",
        "        (batch_size, num_channels, height, width) = input.shape\n",
        "        means = self.means.repeat((batch_size, height, width, 1)).permute(0, 3, 1, 2)\n",
        "        sds = self.sds.repeat((batch_size, height, width, 1)).permute(0, 3, 1, 2)\n",
        "        return (input - means) / sds\n"
      ],
      "metadata": {
        "id": "jNfT-J7Xm8zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate a smoothed classifier on a dataset { form-width: \"200px\" }\n",
        "#@title  { form-width: \"200px\" }\n",
        "#@title  { form-width: \"150px\" }\n",
        "#@title  { form-width: \"50px\" }\n",
        "# evaluate a smoothed classifier on a dataset\n",
        "\n",
        "num_classes = 10\n",
        "sigma = 0.5        #@param {type: \"number\"}\n",
        "dataset = 'cifar10'\n",
        "split = 'test'\n",
        "skip = 1\n",
        "max = 50            #@param {type: \"integer\"}\n",
        "N0 = 100\n",
        "N = 100000\n",
        "alpha = 0.001\n",
        "batch_size = 1000\n",
        "\n",
        "# load the base classifier\n",
        "if torch.cuda.is_available():\n",
        "  model = VGG('VGG19').to(device)\n",
        "  state_dict = torch.load('VGG19_cifar10_rand.pth')\n",
        "  model.load_state_dict(state_dict)\n",
        "else:\n",
        "  model = VGG('VGG19')\n",
        "  state_dict = torch.load('/content/gdrive/MyDrive/VGG19_cifar10_rand.pth', map_location=torch.device('cpu'))\n",
        "  model.load_state_dict(state_dict)\n",
        "\n",
        "# create the smooothed classifier g\n",
        "smoothed_classifier = Smooth(model, num_classes, sigma)\n",
        "\n",
        "# Set output file path\n",
        "outfile_path = \"/content/gdrive/MyDrive/output_cifar10_rand_sigma_\"+str(sigma)+\"_samples\"+str(max)+\".txt\"\n",
        "\n",
        "# Create the output file if it doesn't exist\n",
        "if not os.path.exists(outfile_path):\n",
        "    with open(outfile_path, 'w') as f:\n",
        "        pass\n",
        "\n",
        "# Open file and write header\n",
        "with open(outfile_path, 'a') as f:\n",
        "    print(\"idx\\tlabel\\tpredict\\tradius\\tcorrect\\ttime\", file=f, flush=True)\n",
        "    # Add your additional code to write information to the file here\n",
        "\n",
        "# iterate through the dataset\n",
        "dataset = get_dataset(dataset, split)\n",
        "for i in range(len(dataset)):\n",
        "\n",
        "    # only certify every args.skip examples, and stop after args.max examples\n",
        "    if i % skip != 0:\n",
        "        continue\n",
        "    if i == max:\n",
        "        break\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    (x, label) = dataset[i]\n",
        "\n",
        "    before_time = time()\n",
        "    # certify the prediction of g around x\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    else:\n",
        "        x = x\n",
        "\n",
        "    prediction, radius = smoothed_classifier.certify(x, N0, N, alpha, batch_size)\n",
        "    after_time = time()\n",
        "    correct = int(prediction == label)\n",
        "\n",
        "    time_elapsed = str(datetime.timedelta(seconds=(after_time - before_time)))\n",
        "    with open(outfile_path, 'a') as f:\n",
        "        print(\"{}\\t{}\\t{}\\t{:.3}\\t{}\\t{}\".format(\n",
        "            i, label, prediction, radius, correct, time_elapsed), file=f, flush=True)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "RbBEHs1skDWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97864c4e-4f6b-4962-e68e-b0ca39cdee32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Files already downloaded and verified\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot results { form-width: \"200px\" }\n",
        "sns.set()\n",
        "\n",
        "class Accuracy(object):\n",
        "    def at_radii(self, radii: np.ndarray):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class ApproximateAccuracy(Accuracy):\n",
        "    def __init__(self, data_file_path: str):\n",
        "        self.data_file_path = data_file_path\n",
        "\n",
        "    def at_radii(self, radii: np.ndarray) -> np.ndarray:\n",
        "        df = pd.read_csv(self.data_file_path, delimiter=\"\\t\")\n",
        "        return np.array([self.at_radius(df, radius) for radius in radii])\n",
        "\n",
        "    def at_radius(self, df: pd.DataFrame, radius: float):\n",
        "        return (df[\"correct\"] & (df[\"radius\"] >= radius)).mean()\n",
        "\n",
        "\n",
        "class HighProbAccuracy(Accuracy):\n",
        "    def __init__(self, data_file_path: str, alpha: float, rho: float):\n",
        "        self.data_file_path = data_file_path\n",
        "        self.alpha = alpha\n",
        "        self.rho = rho\n",
        "\n",
        "    def at_radii(self, radii: np.ndarray) -> np.ndarray:\n",
        "        df = pd.read_csv(self.data_file_path, delimiter=\"\\t\")\n",
        "        return np.array([self.at_radius(df, radius) for radius in radii])\n",
        "\n",
        "    def at_radius(self, df: pd.DataFrame, radius: float):\n",
        "        mean = (df[\"correct\"] & (df[\"radius\"] >= radius)).mean()\n",
        "        num_examples = len(df)\n",
        "        return (mean - self.alpha - math.sqrt(self.alpha * (1 - self.alpha) * math.log(1 / self.rho) / num_examples)\n",
        "                - math.log(1 / self.rho) / (3 * num_examples))\n",
        "\n",
        "\n",
        "class Line(object):\n",
        "    def __init__(self, quantity: Accuracy, legend: str, plot_fmt: str = \"\", scale_x: float = 1):\n",
        "        self.quantity = quantity\n",
        "        self.legend = legend\n",
        "        self.plot_fmt = plot_fmt\n",
        "        self.scale_x = scale_x\n",
        "\n",
        "\n",
        "def plot_certified_accuracy(outfile: str, title: str, max_radius: float,\n",
        "                            lines: List[Line], radius_step: float = 0.01) -> None:\n",
        "    radii = np.arange(0, max_radius + radius_step, radius_step)\n",
        "    plt.figure()\n",
        "    print(\"max_radius: \"+str(max_radius))\n",
        "    print(\"radius step: \"+str(radius_step))\n",
        "    print(\"title: \"+str(title))\n",
        "    for line in lines:\n",
        "        plt.plot(radii * line.scale_x, line.quantity.at_radii(radii), line.plot_fmt)\n",
        "\n",
        "    plt.ylim((0, 1))\n",
        "    plt.xlim((0, max_radius))\n",
        "    plt.tick_params(labelsize=14)\n",
        "    plt.xlabel(\"radius\", fontsize=16)\n",
        "    plt.ylabel(\"certified accuracy\", fontsize=16)\n",
        "    plt.legend([method.legend for method in lines], loc='upper right', fontsize=16)\n",
        "    plt.savefig(outfile + \".pdf\")\n",
        "    plt.tight_layout()\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outfile + \".png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def smallplot_certified_accuracy(outfile: str, title: str, max_radius: float,\n",
        "                                 methods: List[Line], radius_step: float = 0.01, xticks=0.5) -> None:\n",
        "    radii = np.arange(0, max_radius + radius_step, radius_step)\n",
        "    plt.figure()\n",
        "    for method in methods:\n",
        "        plt.plot(radii, method.quantity.at_radii(radii), method.plot_fmt)\n",
        "\n",
        "    plt.ylim((0, 1))\n",
        "    plt.xlim((0, max_radius))\n",
        "    plt.xlabel(\"radius\", fontsize=22)\n",
        "    plt.ylabel(\"certified accuracy\", fontsize=22)\n",
        "    plt.tick_params(labelsize=20)\n",
        "    plt.gca().xaxis.set_major_locator(plt.MultipleLocator(xticks))\n",
        "    plt.legend([method.legend for method in methods], loc='upper right', fontsize=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outfile + \".pdf\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def latex_table_certified_accuracy(outfile: str, radius_start: float, radius_stop: float, radius_step: float,\n",
        "                                   methods: List[Line]):\n",
        "    radii = np.arange(radius_start, radius_stop + radius_step, radius_step)\n",
        "    accuracies = np.zeros((len(methods), len(radii)))\n",
        "    for i, method in enumerate(methods):\n",
        "        accuracies[i, :] = method.quantity.at_radii(radii)\n",
        "\n",
        "    f = open(outfile, 'w')\n",
        "\n",
        "    for radius in radii:\n",
        "        f.write(\"& $r = {:.3}$\".format(radius))\n",
        "    f.write(\"\\\\\\\\\\n\")\n",
        "\n",
        "    f.write(\"\\midrule\\n\")\n",
        "\n",
        "    for i, method in enumerate(methods):\n",
        "        f.write(method.legend)\n",
        "        for j, radius in enumerate(radii):\n",
        "            if i == accuracies[:, j].argmax():\n",
        "                txt = r\" & \\textbf{\" + \"{:.2f}\".format(accuracies[i, j]) + \"}\"\n",
        "            else:\n",
        "                txt = \" & {:.2f}\".format(accuracies[i, j])\n",
        "            f.write(txt)\n",
        "        f.write(\"\\\\\\\\\\n\")\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def markdown_table_certified_accuracy(outfile: str, radius_start: float, radius_stop: float, radius_step: float,\n",
        "                                      methods: List[Line]):\n",
        "    radii = np.arange(radius_start, radius_stop + radius_step, radius_step)\n",
        "    accuracies = np.zeros((len(methods), len(radii)))\n",
        "    for i, method in enumerate(methods):\n",
        "        accuracies[i, :] = method.quantity.at_radii(radii)\n",
        "\n",
        "    f = open(outfile, 'w')\n",
        "    f.write(\"|  | \")\n",
        "    for radius in radii:\n",
        "        f.write(\"r = {:.3} |\".format(radius))\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"| --- | \")\n",
        "    for i in range(len(radii)):\n",
        "        f.write(\" --- |\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    for i, method in enumerate(methods):\n",
        "        f.write(\"<b> {} </b>| \".format(method.legend))\n",
        "        for j, radius in enumerate(radii):\n",
        "            if i == accuracies[:, j].argmax():\n",
        "                txt = \"{:.2f}<b>*</b> |\".format(accuracies[i, j])\n",
        "            else:\n",
        "                txt = \"{:.2f} |\".format(accuracies[i, j])\n",
        "            f.write(txt)\n",
        "        f.write(\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "#def plot_certified_accuracy(outfile: str, title: str, max_radius: float, lines: List[Line], radius_step: float = 0.01)\n",
        "if __name__ == \"__main__\":\n",
        "    plot_certified_accuracy(\n",
        "        \"/content/gdrive/MyDrive/analysis/latex/results_rand\", \"VGG19 trained with varying noise distributions\", 1.5,  [\n",
        "            Line(ApproximateAccuracy(\"/content/gdrive/MyDrive/output_cifar10_rand_sigma_0.12_samples50.txt\"), \"$\\sigma = 0.12$\"),\n",
        "            Line(ApproximateAccuracy(\"/content/gdrive/MyDrive/output_cifar10_rand_sigma_0.25_samples50.txt\"), \"$\\sigma = 0.25$\"),\n",
        "            Line(ApproximateAccuracy(\"/content/gdrive/MyDrive/output_cifar10_rand_sigma_0.5_samples50.txt\"), \"$\\sigma = 0.50$\"),\n",
        "            Line(ApproximateAccuracy(\"/content/gdrive/MyDrive/output_cifar10_rand_sigma_1.0_samples50.txt\"), \"$\\sigma = 1.00$\"),\n",
        "        ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5eL_k0nqQjA",
        "outputId": "7770babf-9041-442d-ca51-26ab601bc946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_radius: 1.5\n",
            "radius step: 0.01\n",
            "title: VGG19 trained with varying noise distributions\n"
          ]
        }
      ]
    }
  ]
}